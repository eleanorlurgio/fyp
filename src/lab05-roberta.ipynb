{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58140ae-c3d5-492a-ad88-4ddb0a86efdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.htmlNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.11.0+cu113 (from versions: 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1)\n",
      "ERROR: No matching distribution found for torch==1.11.0+cu113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (8.1.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (4.66.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipywidgets) (8.21.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: filelock in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from requests->transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install torch==1.11.0+cu113 torchdata==0.3.0 torchtext==0.12.0 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "%pip install ipywidgets transformers tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32fb9833-d824-45c5-88f4-53d0e0a07980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  2.2.1+cu118\n",
      "torchtext Version:  0.17.1+cpu\n",
      "Using GPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "# Set a fixed value for the random seed to ensure reproducible results\n",
    "SEED = 1234\n",
    "# Determine whether a CUDA-compatible GPU is available, and use it if so; otherwise, use the CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Apply the fixed random seed to PyTorch to ensure consistent initialization and random operations\n",
    "torch.manual_seed(SEED)\n",
    "# Ensure that any operations performed by cuDNN (a GPU-acceleration library used by PyTorch) are deterministic,\n",
    "# which can help in reproducing results but may reduce performance\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"torchtext Version: \", torchtext.__version__)\n",
    "print(f\"Using {'GPU' if str(DEVICE) == 'cuda' else 'CPU'}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840c02bb-713e-4548-9d03-caad108c312d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipywidgets) (8.21.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: decorator in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\elean\\vs-code-workspace\\fyp\\venv\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets\n",
    "# %jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c22d3f-6788-477d-b97e-db7824de5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dbb4b06-589d-4f24-b9c0-98b17b461f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fa36312-4922-4d5f-9b26-dca8162775d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = tokenizer.tokenize('Hello WORLD how ARE yoU?')\n",
    "\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26ab7f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[0, 42891, 232, 2]], 'attention_mask': [[1, 1, 1, 1]]}\n",
      "{'input_ids': [[0, 42891, 50117, 8331, 2]], 'attention_mask': [[1, 1, 1, 1, 1]]}\n",
      "{'input_ids': [[0, 50118, 1437, 1437, 1437, 20760, 50118, 1437, 1437, 1437, 232, 50118, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# original input string\n",
    "print(tokenizer(['hello world']))\n",
    "\n",
    "# input string with tab (\\t) character\n",
    "print(tokenizer(['hello\tworld']))\n",
    "\n",
    "# input string with newline (\\n) character\n",
    "print(tokenizer(['''\n",
    "    hello\n",
    "    world\n",
    "''']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d11d610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[0, 42891, 6, 232, 328, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(['hello, world!']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d24996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 42891, 232, 26964, 13859, 2]]\n",
      "Token with id 100: I\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print only the 'input_ids'\n",
    "print(tokenizer(['hello world ðŸ‘‹'])['input_ids'])\n",
    "\n",
    "# Use f-string for formatting (Python 3.6+) to access the token corresponding to id 100\n",
    "token_with_id_100 = list(tokenizer.get_vocab().keys())[list(tokenizer.get_vocab().values()).index(100)]\n",
    "print(f\"Token with id 100: {token_with_id_100}\")\n",
    "\n",
    "## Or, if you're using an older version of Python, use the .format() method\n",
    "#print(\"Token with id 100: {}\".format(token_with_id_100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af3e7ff-da82-4f84-9b3a-3f1a68b9da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = tokenizer.tokenize('Hello WORLD how ARE yoU?')\n",
    "\n",
    "# indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "# print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb547129-b732-4826-aa02-e88e9e242b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> </s> <pad> <unk>\n"
     ]
    }
   ],
   "source": [
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceec3971-9284-4a64-8c87-8385d6edf0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 1 3\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b690199-5a23-4bd4-ae4e-0bbce58b4310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 1 3\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2392ed9-d43b-40cc-955f-8bc503bd05e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['roberta-base']\n",
    "\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d6a9f50-fc13-4718-aca3-4401b04f593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "class TransformerTokenizer(torch.nn.Module):\n",
    "    def __init__(self, tokenizer):\n",
    "        super().__init__()  # Initialize the superclass (torch.nn.Module)\n",
    "        self.tokenizer = tokenizer  # Store the tokenizer object for later use\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if isinstance(input, list):\n",
    "            tokens = [] \n",
    "            for text in input:  # Iterate over each string in the input list\n",
    "                tokens.append(self.tokenizer.tokenize(text))\n",
    "            return tokens  # Return the list of lists of tokens\n",
    "        elif isinstance(input, str):\n",
    "            return self.tokenizer.tokenize(input)\n",
    "        raise ValueError(f\"Type {type(input)} is not supported.\")\n",
    "        \n",
    "tokenizer_vocab = vocab(tokenizer.vocab, min_freq=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4772cb-d81a-4ef5-877c-3dba1bd7e173",
   "metadata": {},
   "source": [
    "We will then define our text processing pipeline.\n",
    "\n",
    "1. First we use the tokenizer to tokenize the text.\n",
    "2. Then we convert each token to its vocabulary ID.\n",
    "3. We will then cut the text to a maximum length. Note that the actual length we truncate to is 2 tokens shorter than the maximum length allowed by the model. This is because we will add two more tokens, one at the begginning and one at the end.\n",
    "4. Add the Beginning of Sentence token a the beginning.\n",
    "5. Add the End of Sentence token at the end.\n",
    "6. Convert to tensor and pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c9c42bf-ff8c-4746-87d1-4d4bf3e67b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): TransformerTokenizer()\n",
      "  (1): VocabTransform(\n",
      "    (vocab): Vocab()\n",
      "  )\n",
      "  (2): Truncate()\n",
      "  (3): AddToken()\n",
      "  (4): AddToken()\n",
      "  (5): ToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchtext.transforms as T\n",
    "\n",
    "text_transform = T.Sequential(\n",
    "    TransformerTokenizer(tokenizer),  # Tokenize\n",
    "    T.VocabTransform(tokenizer_vocab),  # Conver to vocab IDs\n",
    "    T.Truncate(max_input_length - 2),  # Cut to max length to add BOS and EOS token\n",
    "    T.AddToken(token=tokenizer_vocab[init_token], begin=True),  # BOS token\n",
    "    T.AddToken(token=tokenizer_vocab[eos_token], begin=False),  # EOS token\n",
    "    T.ToTensor(padding_value=tokenizer_vocab[pad_token]),  # Convert to tensor and pad\n",
    ")\n",
    "\n",
    "print(text_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19452267-7dc9-49fa-92f1-6de1535fe3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# using the split version of the dataset\n",
    "dataset = load_dataset(\"dair-ai/emotion\", \"split\")\n",
    "\n",
    "train_data = to_map_style_dataset(dataset[\"train\"])\n",
    "valid_data = to_map_style_dataset(dataset[\"validation\"])\n",
    "test_data = to_map_style_dataset(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e05079d-8b7c-44bd-a20e-67da95dcd30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train data: 16000\n",
      "Full val data: 2000\n",
      "Full test data: 2000\n"
     ]
    }
   ],
   "source": [
    "# from torch.utils.data import random_split\n",
    "\n",
    "print(\"Full train data:\", len(train_data))\n",
    "print(\"Full val data:\", len(valid_data))\n",
    "print(\"Full test data:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cc15932-50c1-4902-bbd8-b6f4e9297f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "labels = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "# labels = ['sadness', 'joy']\n",
    "label_vocab = vocab(OrderedDict([(label, 1) for label in labels])) #the frequency for each label is set to 1\n",
    "\n",
    "# default_index = -1\n",
    "# label_vocab.set_default_index(default_index)\n",
    "# # assign default unknown token\n",
    "# label_vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "610dab91-2a58-4df5-8dce-967a7ccc2803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 3, 'sadness': 0, 'joy': 1, 'love': 2, 'fear': 4, 'surprise': 5}\n"
     ]
    }
   ],
   "source": [
    "print(label_vocab.get_stoi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a63d09c8-1db9-4f12-8b4f-62055b0e6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_transform = T.Sequential(\n",
    "    T.LabelToIndex(label_vocab.get_itos()),  # Convert to integer\n",
    "    T.ToTensor(),  # Convert to tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12f0b657-c75d-427b-9881-a5b5fbeb989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def collate_batch(batch):\n",
    "    labels, texts = zip(*batch)\n",
    "\n",
    "    new_labels = []\n",
    "    for x in labels:\n",
    "        if x == \"sadness\":\n",
    "            new_labels.append(0)\n",
    "        elif x == \"joy\":\n",
    "            new_labels.append(1)\n",
    "        elif x == \"love\":\n",
    "            new_labels.append(2)\n",
    "        elif x == \"anger\":\n",
    "            new_labels.append(3)\n",
    "        elif x == \"fear\":\n",
    "            new_labels.append(4)\n",
    "        elif x == \"surprise\":\n",
    "            new_labels.append(5)\n",
    "    \n",
    "    labels = label_transform(new_labels)\n",
    "    \n",
    "    texts = text_transform(list(texts))\n",
    "\n",
    "    return labels.float().to(DEVICE), texts.to(DEVICE)\n",
    "\n",
    "def _get_dataloader(data):\n",
    "    return DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "train_dataloader:DataLoader = _get_dataloader(train_data)\n",
    "valid_dataloader = _get_dataloader(valid_data)\n",
    "test_dataloader = _get_dataloader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3175f53-827a-4d97-a89b-b9bfb3807f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "roberta = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5700fd1-7246-4d55-abf4-fd47a335f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RoBERTaGRUSentiment(nn.Module):\n",
    "    def __init__(self, roberta, hidden_dim, output_dim, n_layers, bidirectional, dropout):        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.roberta = roberta\n",
    "\n",
    "        # roberta's hidden_size is 768 by default\n",
    "        self.embedding_dim = roberta.config.to_dict()['hidden_size']\n",
    "\n",
    "        print(\"self.embedding_dim\", self.embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(self.embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedded = self.roberta(text)[0]\n",
    "        \n",
    "        _, hidden = self.rnn(embedded)\n",
    "                \n",
    "\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "\n",
    "        print(\"self.out(hidden)\", self.out(hidden))\n",
    "\n",
    "        # hidden has shape 2\n",
    "        return self.out(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a1f17b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# class RoBERTaGRUClassifier(nn.Module):\n",
    "#     def __init__(self, num_labels, hidden_size=768, gru_hidden_size=128):\n",
    "#         super(RoBERTaGRUClassifier, self).__init__()\n",
    "#         self.roberta = roberta\n",
    "#         self.gru = nn.GRU(input_size=hidden_size, hidden_size=gru_hidden_size, batch_first=True)\n",
    "#         self.fc = nn.Linear(gru_hidden_size, num_labels)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask=None):\n",
    "#         # Get RoBERTa embeddings\n",
    "#         outputs = self.roberta(input_ids)\n",
    "#         last_hidden_state = outputs['last_hidden_state']  # Shape: (batch_size, seq_len, hidden_size)\n",
    "\n",
    "#         # Pool the last hidden state (CLS token)\n",
    "#         pooled_output = last_hidden_state[:, 0, :]  # Shape: (batch_size, hidden_size)\n",
    "\n",
    "#         # Pass through GRU\n",
    "#         gru_output, _ = self.gru(pooled_output.unsqueeze(1))\n",
    "#         gru_output = gru_output.squeeze(1)  # Shape: (batch_size, gru_hidden_size)\n",
    "\n",
    "#         # Classification layer\n",
    "#         logits = self.fc(gru_output)  # Shape: (batch_size, num_labels)\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e5de1de9-1167-4f23-8cfd-a5e5d1f78357",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 128  # 254 is better, less than 64 is no very favourable.\n",
    "OUTPUT_DIM = 6  # We only need one neuron as output\n",
    "N_LAYERS = 1\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "# model = RoBERTaGRUClassifier(roberta, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "model = RoBERTaGRUClassifier(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "00ece71f-d134-442f-a010-5b7103034201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 345,606 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "#parameters refer to the internal variables that are learned during the training process. \n",
    "#For a neural network model, \n",
    "#parameters typically include weights and biases associated with each layer of the network.\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "16c933fe-4de3-4ba9-aece-5bc876ba4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('roberta'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bf1fe1fa-4cd8-4d9f-bce2-703cbe992bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 345,606 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "10fb0801-3dfa-4327-b2f4-90a5c21c8b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru.weight_ih_l0\n",
      "gru.weight_hh_l0\n",
      "gru.bias_ih_l0\n",
      "gru.bias_hh_l0\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5e58bfb1-9b40-4a4b-a483-e5f995289cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a3595f3e-dd1c-46ee-8a80-21c118582ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "275d741f-f28c-4d2f-8033-61ffb7465e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "87dd3ecd-7e5a-4d7e-b365-4f7e44544f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9cec7d4a-1f45-4543-8fd6-b196efaab142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, iterator:DataLoader, optimizer, criterion):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm(iterator, desc=\"\\tTraining\"):\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        labels, texts = batch  # Note that this has to match the order in collate_batch\n",
    "\n",
    "        new_labels = []\n",
    "        for x in labels:\n",
    "            if x == \"sadness\":\n",
    "                new_labels.append(0)\n",
    "            elif x == \"joy\":\n",
    "                new_labels.append(1)\n",
    "            elif x == \"love\":\n",
    "                new_labels.append(2)\n",
    "            elif x == \"anger\":\n",
    "                new_labels.append(3)\n",
    "            elif x == \"fear\":\n",
    "                new_labels.append(4)\n",
    "            elif x == \"surprise\":\n",
    "                new_labels.append(5)\n",
    "\n",
    "        predictions = model(texts).squeeze(1)\n",
    "        loss = criterion(predictions, new_labels)\n",
    "\n",
    "        ################################# binary???\n",
    "        acc = binary_accuracy(predictions, new_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "66605c0b-9bd5-4519-8a1c-aec29f7a945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(iterator, desc=\"\\tEvaluation\"):\n",
    "            labels, texts = batch  # Note that this has to match the order in collate_batch\n",
    "\n",
    "            new_labels = []\n",
    "            for x in labels:\n",
    "                if x == \"sadness\":\n",
    "                    new_labels.append(0)\n",
    "                elif x == \"joy\":\n",
    "                    new_labels.append(1)\n",
    "                elif x == \"love\":\n",
    "                    new_labels.append(2)\n",
    "                elif x == \"anger\":\n",
    "                    new_labels.append(3)\n",
    "                elif x == \"fear\":\n",
    "                    new_labels.append(4)\n",
    "                elif x == \"surprise\":\n",
    "                    new_labels.append(5)\n",
    "                \n",
    "\n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, new_labels)\n",
    "            acc = binary_accuracy(predictions, new_labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e2cbbab1-8436-4a0d-9570-67c977e32191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9b7e8055-c612-4206-81c2-f9e0d774018c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU for training.\n",
      "Epoch: 01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining:   0%|          | 0/250 [00:00<?, ?it/s]c:\\Users\\elean\\vs-code-workspace\\fyp\\venv\\Lib\\site-packages\\torch\\_jit_internal.py:1358: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n",
      "\tTraining:   0%|          | 0/250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[179], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 11\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m valid_loss, valid_acc \u001b[38;5;241m=\u001b[39m evaluate(model, valid_dataloader, criterion)\n",
      "Cell \u001b[1;32mIn[176], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurprise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     27\u001b[0m         new_labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(predictions, new_labels)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m################################# binary???\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elean\\vs-code-workspace\\fyp\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elean\\vs-code-workspace\\fyp\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[166], line 15\u001b[0m, in \u001b[0;36mRoBERTaGRUClassifier.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Get RoBERTa embeddings\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroberta(input_ids)\n\u001b[1;32m---> 15\u001b[0m     last_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_hidden_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Shape: (batch_size, seq_len, hidden_size)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Pool the last hidden state (CLS token)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m last_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# Shape: (batch_size, hidden_size)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elean\\vs-code-workspace\\fyp\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:401\u001b[0m, in \u001b[0;36mModelOutput.__getitem__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(k, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    400\u001b[0m     inner_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_tuple()[k]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "print(f\"Using {'GPU' if str(DEVICE) == 'cuda' else 'CPU'} for training.\")\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    \n",
    "    valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'transformer-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda5694-5973-4267-84f7-d7571859f318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('transformer-model.pt'))\n",
    "\n",
    "# If you want to load a model trained on a GPU, but the current device is on CPU, then you need to explicitly state that\n",
    "# >>> model.load_state_dict(torch.load('tut6-model.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fbd71d-96e1-4b64-b032-9ce49a32b400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tEvaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:22<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.614 | Test Acc: 68.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_dataloader, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c9f993-24cb-4831-a9a1-4e1ea1d41d4f",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We'll then use the model to test the sentiment of some sequences. We tokenize the input sequence, trim it down to the maximum length, add the special tokens to either side, convert it to a tensor, add a fake batch dimension and then pass it through our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91d7ea-acd7-4418-99e2-be6e4e4b3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    processed_sentence = text_transform([sentence]).to(DEVICE)\n",
    "    prediction = torch.sigmoid(model(processed_sentence))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cac87a-fde0-4de1-9f79-028047b36c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2504885196685791"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0526614-6882-48b2-a23b-fcb458a24dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9023417234420776"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a2fd9-87c3-451e-ae04-a00a3c37a668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
